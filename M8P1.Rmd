---
title: "Practical Machine Learning - Project"
author: "Author J"
date: "Sunday, April 26, 2015"
output: word_document
---

#Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 

##Data 

The training data for this project are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here: 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 


##Load Library

```{r}
library(caret)
library(randomForest)
```

##Read files and Clean up data
```{r}
data <- read.csv(file= "pml-training.csv", header= TRUE, sep = ",", na.strings= c("","NA"))
```


Remove columns 1-7 as it is non numerical data
```{r}
data <- data[,-(1:7)]
```


Remove NA
```{r}
data <- data[,which(as.numeric(colSums(is.na(data)))==0)]
```


Remove near zero variance columns as it would meaningless
```{r}
end <- ncol(data)
data[,-end] <- data.frame(sapply(data[,-end], as.numeric))
nzv <- nearZeroVar(data[, -end], saveMetrics=TRUE)
data <- data[,!as.logical(nzv$nzv)]
```


##Data Processing

Partition data
```{r}
set.seed(888)
inTrain<-createDataPartition(y=data$classe, p=0.6, list=FALSE)
train <- data[inTrain,]
validation <- data[-inTrain,]
```


Fitting a model to predict classe and everything else as a predictor
```{r}
rfModel <- randomForest(classe ~ ., data = train)

ptrain <- predict(rfModel, train)
print(confusionMatrix(ptrain, train$classe))

```


##Validation the 40% of the remaining data
The model is used to classify the remaining 40% of data. The results were placed in a confusion matrix along with the actual classifications in order to determine the accuracy of the model.

```{r}
pvalidation <- predict(rfModel, validation)
print(confusionMatrix(pvalidation, validation$classe))
```
The model has an accuracy of 99.4%. The out of sample range is 0.6% which shows that the model is robust and adequate to predict the new data.

#Final Test Set

The model tested is now used to predict the 20 test data set. 

```{r}
predictionTest <- read.csv(file= "pml-testing.csv", header= TRUE, sep = ",",na.strings= c("","NA"))

ptest <- predict(rfModel, predictionTest)
ptest
```

#Conclusion
The accuracy of the model with 99.4% accuracy provided the following predictions:

 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 
 B  A  B  A  A  E  D  B  A  A  B  C  B  A  E  E  A  B  B  B 


